# Issue Jo Mene Face Kre
1. Phele To Ye At the Time of Dynamic Load balancer mutiple process are running
concurrently so whenever i push some data on the redis pub subs model a single data leads to generation of 4 data beacuse every cluster working simuntanously over here which creates a problem of storing these huge data in redis as well as in queue also

2. Second things i face out that which library or if there exist some other mechanism to generate the unqiue api key and secret hash for the users but i came up with the crypto module but i was looking somethings different but at last i used crypto module for api key generating and hash secret

3. Third thing i face out is how we are able to generate the user , file , api , analaysis unqiue id to figure them out one thing i came up that either we can use date with milliseconds time but thats not an apporpriate for this so again crypto help us to generate the random bytes for user which are unqiue in nature in future we can also implement our own algorithm

4. Next things is that basically i have to figure out whats param should be taken to generate the signed url for the so the best things is to take user id and its api secret hash for the same we can apply the digital signature to that and send back to it but the issue i faced in that i was able to create the signed url but only with 2 data that was not enough for backend and future presective for the same reason i also append the filePath and exp polciy to the signed url

5. One Toughest problem for me is to veirfy the signed url as a fresher in backend developer i send the signed url to the client as exp policy is also the part i have mention above the exp with Date.now() which return the number but when we are sending the data it becomes string as i have make the aspi_secret with Number(exp) and at the time of verification i was verifying the payload with String(exp) which total chnages the hash code from crypto this this me as 35 Min to solve it out but i figure out the problem by own but for confirmation i do chatgpt and kimi and yes its the problem of type casting at data sharing between network

6. Another Problem i faced is for acheiving the smoothness and scalabilty basically i used string key value data structure of redis to put the signature of current signed url with so that we i can first match the signature from cache server instead of making an api call to database for fetching the api secret then create hash code for verififcation beacuse it may possible that api sercet may be modify by client this help me to reuce the no of db calls by 7% and latecy by 2%

7. After successful files upload with end destination the another problem was if the file contains virus or its an malicious or suspicious file in this scenarios it can be harmful for the server so i created i redis pub sub model for real time and faster deleivy of the message from api server to BullMq Services and queue services runs at background for virus scan as soon as the queue find its and dangrous file it instantly remove it from the server and after that Append a log in data base for the same

8. Issue I Face at time of server and api layer security for implemnting the rate limit for protecting the server DOS attack the issue is that i was limiting out the 
user on the basis of their ip address but the issue is not that issue is i thought for a while and relaise that whenever out app is live on production server in this scenarios the req from client will not directly hit to our server even though we are pushing our app on netlify vercel or any other the req will go through the middle layer like client -> req -> (CDN / Proxy) -> origin server so server is behind of CDN and Proxy which means the req will be delegated by them for the same reason the cleint for server is not actual user it will be the CDN & Proxy server findign out the solution for this in google and kimi i received a solution that in these CDN & proxy keeps the user actual ip address in their sepcial headers but these headers generaly ignore bu express due to its own security reason so to achive the same we have to provide the knowlegde to express server that hey you should trust out the proxy in app app.set('trust proxy' , true) by doing this so we can get user actual ip 
in req.ip attribute  

To Addmore if you want to knwo why req behaves like this client -> req -> (CDN / Proxy) -> origin server this is done so beacuse to provide the data or static files to the client if faster manner these servers caches the static file like html js css or other images videos for temp basis only not permananet and for proxy server for protecting your origin server from bots or hackers and to provide smoother network flow

9.The most important thing i learned while creationg of system is that optimizing and scaling the system is good as well as optimizing the database is also good but the thing to be consider that what datatype and how you are storing the data into database For exmaple The I faced out is i have implemenetd the shared with attribute as a array of the data shared to that people but the issue is that if we want to find whether that particular file let say Person A share file(X) is shared to person B now we want to find whether its true that file is shared or not we have to traverse the O(N) time in an array this leads me the newtork latency from 20ms toh 73ms but as of know the system is created on same thing so i am not going to replace it but yeah in future i will remember about the same and try to implement somthing more efficent like if data is stored in sorted form so that we can apply binary search O(logn) time  
---
Yeah i am currently also implementing the on process virus scan check service without receivng that file on the server but this lead me to a higher cost and more complex logic still trying....

